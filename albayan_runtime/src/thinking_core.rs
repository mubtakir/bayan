//! ThinkingCore - Ù…Ø­Ù„Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠ
//! ØªÙ†ÙÙŠØ° Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ø«Ø§Ù„Ø«Ø©: Ø¨Ù†Ø§Ø¡ Ù…Ø­Ù„Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠ
//! Expert recommendation: Priority 3 - Build Initial Word Analyzer

use std::collections::HashMap;
use std::sync::{Mutex, OnceLock};
use crate::linguistic_db::{get_linguistic_analyzer, WordSemanticSignature};

/// Ù†ÙˆØ§Ø© Ø§Ù„ØªÙÙƒÙŠØ± - Ù…Ø­Ù„Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ
/// ThinkingCore - Revolutionary Semantic Word Analyzer
#[derive(Debug, Clone)]
pub struct ThinkingCore {
    /// ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ù†Ø¬Ø²Ø©
    analysis_history: Vec<ThinkingWordAnalysisResult>,
    /// Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
    performance_stats: PerformanceStats,
    /// Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„
    analysis_settings: AnalysisSettings,
}

/// Ù†ØªÙŠØ¬Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø© - Ù†ÙˆØ§Ø© Ø§Ù„ØªÙÙƒÙŠØ±
/// Word Analysis Result - ThinkingCore
#[derive(Debug, Clone)]
pub struct ThinkingWordAnalysisResult {
    /// Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø­Ù„Ù„Ø©
    pub word: String,
    /// Ø§Ù„Ù„ØºØ©
    pub language: String,
    /// Ø§Ù„ØªÙˆÙ‚ÙŠØ¹ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ
    pub semantic_signature: Vec<String>,
    /// Ù‚ÙˆØ© Ø§Ù„ØªÙˆÙ‚ÙŠØ¹ (0.0 - 1.0)
    pub signature_strength: f64,
    /// ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ø§Ù‚Ø©
    pub energy_analysis: String,
    /// Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†
    pub dominant_element: String,
    /// Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„ÙØ±Ø¯ÙŠØ©
    pub character_semantics: Vec<CharacterAnalysis>,
    /// Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø³ØªØºØ±Ù‚ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ (Ù…ÙŠÙƒØ±ÙˆØ«Ø§Ù†ÙŠØ©)
    pub analysis_time_microseconds: u64,
}

/// ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø±Ù Ø§Ù„ÙØ±Ø¯ÙŠ
/// Individual Character Analysis
#[derive(Debug, Clone)]
pub struct CharacterAnalysis {
    /// Ø§Ù„Ø­Ø±Ù
    pub character: char,
    /// Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„ØµÙˆØª
    pub sound_meanings: Vec<String>,
    /// Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ø´ÙƒÙ„
    pub shape_meanings: Vec<String>,
    /// Ù†ÙˆØ¹ Ø§Ù„Ø·Ø§Ù‚Ø©
    pub energy_type: String,
    /// Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ
    pub natural_element: String,
    /// Ù‚ÙˆØ© Ø§Ù„ØªØ£Ø«ÙŠØ±
    pub influence_strength: f64,
}

/// Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
/// Performance Statistics
#[derive(Debug, Clone)]
pub struct PerformanceStats {
    /// Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
    pub total_analyses: u64,
    /// Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©
    pub successful_analyses: u64,
    /// Ù…ØªÙˆØ³Ø· ÙˆÙ‚Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„ (Ù…ÙŠÙƒØ±ÙˆØ«Ø§Ù†ÙŠØ©)
    pub average_analysis_time: f64,
    /// Ø£Ø³Ø±Ø¹ ØªØ­Ù„ÙŠÙ„ (Ù…ÙŠÙƒØ±ÙˆØ«Ø§Ù†ÙŠØ©)
    pub fastest_analysis: u64,
    /// Ø£Ø¨Ø·Ø£ ØªØ­Ù„ÙŠÙ„ (Ù…ÙŠÙƒØ±ÙˆØ«Ø§Ù†ÙŠØ©)
    pub slowest_analysis: u64,
}

/// Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„
/// Analysis Settings
#[derive(Debug, Clone)]
pub struct AnalysisSettings {
    /// ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚
    pub deep_analysis_enabled: bool,
    /// ØªÙØ¹ÙŠÙ„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ø§Ù‚Ø©
    pub energy_analysis_enabled: bool,
    /// ØªÙØ¹ÙŠÙ„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù†Ø§ØµØ±
    pub element_analysis_enabled: bool,
    /// Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù‚ÙˆØ© Ø§Ù„ØªÙˆÙ‚ÙŠØ¹
    pub minimum_signature_strength: f64,
}

impl Default for AnalysisSettings {
    fn default() -> Self {
        Self {
            deep_analysis_enabled: true,
            energy_analysis_enabled: true,
            element_analysis_enabled: true,
            minimum_signature_strength: 0.1,
        }
    }
}

impl Default for PerformanceStats {
    fn default() -> Self {
        Self {
            total_analyses: 0,
            successful_analyses: 0,
            average_analysis_time: 0.0,
            fastest_analysis: u64::MAX,
            slowest_analysis: 0,
        }
    }
}

impl ThinkingCore {
    /// Ø¥Ù†Ø´Ø§Ø¡ Ù†ÙˆØ§Ø© ØªÙÙƒÙŠØ± Ø¬Ø¯ÙŠØ¯Ø©
    /// Create new ThinkingCore instance
    pub fn new() -> Self {
        Self {
            analysis_history: Vec::new(),
            performance_stats: PerformanceStats::default(),
            analysis_settings: AnalysisSettings::default(),
        }
    }

    /// ØªØ­Ù„ÙŠÙ„ ÙƒÙ„Ù…Ø© - Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    /// Analyze word - Core function
    pub fn analyze_word(&mut self, word: &str, language: &str) -> ThinkingWordAnalysisResult {
        let start_time = std::time::Instant::now();

        // ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.performance_stats.total_analyses += 1;

        // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù„ØºÙˆÙŠØ©
        let semantic_signature = if let Some(mut analyzer) = get_linguistic_analyzer() {
            analyzer.analyze_word(word, language)
        } else {
            // Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆÙ‚ÙŠØ¹ Ø§ÙØªØ±Ø§Ø¶ÙŠ ÙÙŠ Ø­Ø§Ù„Ø© Ø¹Ø¯Ù… ØªÙˆÙØ± Ø§Ù„Ù…Ø­Ù„Ù„
            WordSemanticSignature {
                word: word.to_string(),
                language: language.to_string(),
                semantic_signature: vec!["ØºÙŠØ± Ù…Ø­Ù„Ù„".to_string()],
                signature_strength: 0.0,
                energy_analysis: "ØºÙŠØ± Ù…ØªØ§Ø­".to_string(),
                dominant_element: "ØºÙŠØ± Ù…Ø­Ø¯Ø¯".to_string(),
            }
        };

        // ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„ÙØ±Ø¯ÙŠØ©
        let character_semantics = self.analyze_individual_characters(word, language);

        // Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø³ØªØºØ±Ù‚
        let analysis_time = start_time.elapsed().as_micros() as u64;

        // Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
        let result = ThinkingWordAnalysisResult {
            word: word.to_string(),
            language: language.to_string(),
            semantic_signature: semantic_signature.semantic_signature,
            signature_strength: semantic_signature.signature_strength,
            energy_analysis: semantic_signature.energy_analysis,
            dominant_element: semantic_signature.dominant_element,
            character_semantics,
            analysis_time_microseconds: analysis_time,
        };

        // ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.update_performance_stats(analysis_time, true);

        // Ø­ÙØ¸ ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ®
        self.analysis_history.push(result.clone());

        result
    }

    /// ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„ÙØ±Ø¯ÙŠØ©
    /// Analyze individual characters
    fn analyze_individual_characters(&self, word: &str, language: &str) -> Vec<CharacterAnalysis> {
        let mut character_analyses = Vec::new();

        if let Some(analyzer) = get_linguistic_analyzer() {
            for ch in word.chars() {
                if let Some(char_semantics) = analyzer.get_character_info(ch, language) {
                    character_analyses.push(CharacterAnalysis {
                        character: ch,
                        sound_meanings: char_semantics.sound_meaning.clone(),
                        shape_meanings: char_semantics.shape_meaning.clone(),
                        energy_type: char_semantics.energy_type.clone(),
                        natural_element: char_semantics.natural_element.clone(),
                        influence_strength: char_semantics.influence_strength,
                    });
                } else {
                    // Ø­Ø±Ù ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ
                    character_analyses.push(CharacterAnalysis {
                        character: ch,
                        sound_meanings: vec!["ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ".to_string()],
                        shape_meanings: vec!["ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ".to_string()],
                        energy_type: "ØºÙŠØ± Ù…Ø­Ø¯Ø¯".to_string(),
                        natural_element: "ØºÙŠØ± Ù…Ø­Ø¯Ø¯".to_string(),
                        influence_strength: 0.0,
                    });
                }
            }
        }

        character_analyses
    }

    /// ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
    /// Update performance statistics
    fn update_performance_stats(&mut self, analysis_time: u64, success: bool) {
        if success {
            self.performance_stats.successful_analyses += 1;
        }

        // ØªØ­Ø¯ÙŠØ« Ø£Ø³Ø±Ø¹ ÙˆØ£Ø¨Ø·Ø£ ØªØ­Ù„ÙŠÙ„
        if analysis_time < self.performance_stats.fastest_analysis {
            self.performance_stats.fastest_analysis = analysis_time;
        }
        if analysis_time > self.performance_stats.slowest_analysis {
            self.performance_stats.slowest_analysis = analysis_time;
        }

        // ØªØ­Ø¯ÙŠØ« Ù…ØªÙˆØ³Ø· Ø§Ù„ÙˆÙ‚Øª
        let total_time = self.performance_stats.average_analysis_time * (self.performance_stats.total_analyses - 1) as f64;
        self.performance_stats.average_analysis_time = (total_time + analysis_time as f64) / self.performance_stats.total_analyses as f64;
    }

    /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
    /// Get performance statistics
    pub fn get_performance_stats(&self) -> &PerformanceStats {
        &self.performance_stats
    }

    /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
    /// Get analysis history
    pub fn get_analysis_history(&self) -> &[ThinkingWordAnalysisResult] {
        &self.analysis_history
    }

    /// ØªØ­Ø¯ÙŠØ« Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„
    /// Update analysis settings
    pub fn update_settings(&mut self, settings: AnalysisSettings) {
        self.analysis_settings = settings;
    }

    /// Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØªÙˆÙ‚ÙŠØ¹Ø§Øª Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©
    /// Compare semantic signatures
    pub fn compare_semantic_signatures(&self, word1: &str, word2: &str, language: &str) -> f64 {
        let analysis1 = self.analyze_word_readonly(word1, language);
        let analysis2 = self.analyze_word_readonly(word2, language);

        // Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆÙ‚ÙŠØ¹Ø§Øª Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©
        let common_semantics = analysis1.semantic_signature.iter()
            .filter(|s1| analysis2.semantic_signature.contains(s1))
            .count();

        let total_semantics = analysis1.semantic_signature.len() + analysis2.semantic_signature.len();

        if total_semantics > 0 {
            (2.0 * common_semantics as f64) / total_semantics as f64
        } else {
            0.0
        }
    }

    /// ØªØ­Ù„ÙŠÙ„ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø© ÙÙ‚Ø· (Ù„Ø§ ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª)
    /// Read-only analysis (doesn't affect statistics)
    fn analyze_word_readonly(&self, word: &str, language: &str) -> ThinkingWordAnalysisResult {
        // Ù†Ø³Ø®Ø© Ù…Ø¨Ø³Ø·Ø© Ù„Ù„Ù‚Ø±Ø§Ø¡Ø© ÙÙ‚Ø·
        if let Some(mut analyzer) = get_linguistic_analyzer() {
            let semantic_signature = analyzer.analyze_word(word, language);
            ThinkingWordAnalysisResult {
                word: word.to_string(),
                language: language.to_string(),
                semantic_signature: semantic_signature.semantic_signature,
                signature_strength: semantic_signature.signature_strength,
                energy_analysis: semantic_signature.energy_analysis,
                dominant_element: semantic_signature.dominant_element,
                character_semantics: Vec::new(), // ØªØ¨Ø³ÙŠØ· Ù„Ù„Ù‚Ø±Ø§Ø¡Ø© ÙÙ‚Ø·
                analysis_time_microseconds: 0,
            }
        } else {
            ThinkingWordAnalysisResult {
                word: word.to_string(),
                language: language.to_string(),
                semantic_signature: vec!["ØºÙŠØ± Ù…Ø­Ù„Ù„".to_string()],
                signature_strength: 0.0,
                energy_analysis: "ØºÙŠØ± Ù…ØªØ§Ø­".to_string(),
                dominant_element: "ØºÙŠØ± Ù…Ø­Ø¯Ø¯".to_string(),
                character_semantics: Vec::new(),
                analysis_time_microseconds: 0,
            }
        }
    }
}

/// Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù†ÙˆØ§Ø© Ø§Ù„ØªÙÙƒÙŠØ±
/// Global ThinkingCore state
static GLOBAL_THINKING_CORE: OnceLock<Mutex<ThinkingCore>> = OnceLock::new();

/// ØªÙ‡ÙŠØ¦Ø© Ù†ÙˆØ§Ø© Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ø§Ù…Ø©
/// Initialize global ThinkingCore
pub fn initialize_thinking_core() {
    let thinking_core = ThinkingCore::new();
    let _ = GLOBAL_THINKING_CORE.set(Mutex::new(thinking_core));
    println!("ğŸ§  ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†ÙˆØ§Ø© Ø§Ù„ØªÙÙƒÙŠØ± Ø¨Ù†Ø¬Ø§Ø­!");
}

/// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ÙˆØ§Ø© Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ø§Ù…Ø©
/// Get global ThinkingCore
fn get_thinking_core() -> Option<std::sync::MutexGuard<'static, ThinkingCore>> {
    GLOBAL_THINKING_CORE.get().map(|m| m.lock().unwrap())
}

/// ØªØ­Ù„ÙŠÙ„ ÙƒÙ„Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙˆØ§Ø© Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ø§Ù…Ø©
/// Analyze word using global ThinkingCore
pub fn analyze_word_global(word: &str, language: &str) -> Option<ThinkingWordAnalysisResult> {
    get_thinking_core().map(|mut core| core.analyze_word(word, language))
}

/// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù…Ø©
/// Get global performance statistics
pub fn get_global_performance_stats() -> Option<PerformanceStats> {
    get_thinking_core().map(|core| core.get_performance_stats().clone())
}

// FFI Functions for AlBayan Language Integration
use std::ffi::{CStr, CString, c_char, c_int};

/// ØªØ­Ù„ÙŠÙ„ ÙƒÙ„Ù…Ø© - ÙˆØ§Ø¬Ù‡Ø© FFI
/// Analyze word - FFI interface
#[no_mangle]
pub extern "C" fn albayan_rt_analyze_word_thinking(
    word: *const c_char,
    language: *const c_char,
) -> c_int {
    if word.is_null() || language.is_null() {
        return 0; // ÙØ´Ù„
    }

    let word_str = match unsafe { CStr::from_ptr(word) }.to_str() {
        Ok(s) => s,
        Err(_) => return 0,
    };

    let lang_str = match unsafe { CStr::from_ptr(language) }.to_str() {
        Ok(s) => s,
        Err(_) => return 0,
    };

    match analyze_word_global(word_str, lang_str) {
        Some(_) => 1, // Ù†Ø¬Ø­
        None => 0,    // ÙØ´Ù„
    }
}

/// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ - ÙˆØ§Ø¬Ù‡Ø© FFI
/// Get performance statistics - FFI interface
#[no_mangle]
pub extern "C" fn albayan_rt_get_thinking_performance_stats() -> c_int {
    match get_global_performance_stats() {
        Some(stats) => stats.total_analyses as c_int,
        None => -1,
    }
}

/// Ù…Ù‚Ø§Ø±Ù†Ø© Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª - ÙˆØ§Ø¬Ù‡Ø© FFI
/// Compare word semantics - FFI interface
#[no_mangle]
pub extern "C" fn albayan_rt_compare_word_semantics(
    word1: *const c_char,
    word2: *const c_char,
    language: *const c_char,
) -> f64 {
    if word1.is_null() || word2.is_null() || language.is_null() {
        return 0.0;
    }

    let word1_str = match unsafe { CStr::from_ptr(word1) }.to_str() {
        Ok(s) => s,
        Err(_) => return 0.0,
    };

    let word2_str = match unsafe { CStr::from_ptr(word2) }.to_str() {
        Ok(s) => s,
        Err(_) => return 0.0,
    };

    let lang_str = match unsafe { CStr::from_ptr(language) }.to_str() {
        Ok(s) => s,
        Err(_) => return 0.0,
    };

    if let Some(mut core) = get_thinking_core() {
        core.compare_semantic_signatures(word1_str, word2_str, lang_str)
    } else {
        0.0
    }
}
