// 📚 Phase 2 Examples - FFI & Advanced Linear Algebra
// أمثلة Phase 2 - FFI والجبر الخطي المتقدم

use std::ffi::numpy_ffi::NumPyFFI;
use std::math::advanced_linalg::AdvancedLinAlg;
use std::math::optimization::Optimizer;

// ============================================================
// Example 1: NumPy Array Creation
// ============================================================

fn example_numpy_array_creation() {
    print("═══════════════════════════════════════════════════════");
    print("Example 1: NumPy Array Creation");
    print("═══════════════════════════════════════════════════════");
    
    // Create zeros array
    let zeros = NumPyFFI::zeros(List::from([3, 3]));
    print("Created 3x3 zeros array");
    print("Shape: [3, 3]");
    print("Size: 9");
    
    // Create ones array
    let ones = NumPyFFI::ones(List::from([2, 4]));
    print("Created 2x4 ones array");
    print("Shape: [2, 4]");
    print("Size: 8");
    
    // Create arange
    let arange = NumPyFFI::arange(0.0, 10.0, 1.0);
    print("Created arange(0, 10, 1)");
    print("Size: 10");
    
    // Create linspace
    let linspace = NumPyFFI::linspace(0.0, 1.0, 11);
    print("Created linspace(0, 1, 11)");
    print("Size: 11");
    
    print("");
}

// ============================================================
// Example 2: QR Decomposition
// ============================================================

fn example_qr_decomposition() {
    print("═══════════════════════════════════════════════════════");
    print("Example 2: QR Decomposition");
    print("═══════════════════════════════════════════════════════");
    
    // Create a 3x3 matrix
    let mut A = Matrix::new(3, 3);
    A.set(0, 0, 1.0);
    A.set(0, 1, 2.0);
    A.set(0, 2, 3.0);
    A.set(1, 0, 4.0);
    A.set(1, 1, 5.0);
    A.set(1, 2, 6.0);
    A.set(2, 0, 7.0);
    A.set(2, 1, 8.0);
    A.set(2, 2, 9.0);
    
    print("Original Matrix A:");
    print("[[1, 2, 3]");
    print(" [4, 5, 6]");
    print(" [7, 8, 9]]");
    
    // Compute QR decomposition
    let (Q, R) = AdvancedLinAlg::qr_decomposition(A);
    
    print("QR Decomposition computed");
    print("Q shape: [3, 3]");
    print("R shape: [3, 3]");
    print("Property: A = Q * R");
    
    print("");
}

// ============================================================
// Example 3: Cholesky Decomposition
// ============================================================

fn example_cholesky_decomposition() {
    print("═══════════════════════════════════════════════════════");
    print("Example 3: Cholesky Decomposition");
    print("═══════════════════════════════════════════════════════");
    
    // Create a positive definite matrix
    let mut A = Matrix::new(3, 3);
    A.set(0, 0, 4.0);
    A.set(0, 1, 2.0);
    A.set(0, 2, 1.0);
    A.set(1, 0, 2.0);
    A.set(1, 1, 5.0);
    A.set(1, 2, 2.0);
    A.set(2, 0, 1.0);
    A.set(2, 1, 2.0);
    A.set(2, 2, 3.0);
    
    print("Original Positive Definite Matrix A:");
    print("[[4, 2, 1]");
    print(" [2, 5, 2]");
    print(" [1, 2, 3]]");
    
    // Compute Cholesky decomposition
    let L = AdvancedLinAlg::cholesky_decomposition(A);
    
    print("Cholesky Decomposition computed");
    print("L shape: [3, 3]");
    print("Property: A = L * L^T");
    print("L is lower triangular");
    
    print("");
}

// ============================================================
// Example 4: Eigenvalue Computation
// ============================================================

fn example_eigenvalue_computation() {
    print("═══════════════════════════════════════════════════════");
    print("Example 4: Eigenvalue Computation (Power Iteration)");
    print("═══════════════════════════════════════════════════════");
    
    // Create a symmetric matrix
    let mut A = Matrix::new(3, 3);
    A.set(0, 0, 2.0);
    A.set(0, 1, 1.0);
    A.set(0, 2, 0.0);
    A.set(1, 0, 1.0);
    A.set(1, 1, 3.0);
    A.set(1, 2, 1.0);
    A.set(2, 0, 0.0);
    A.set(2, 1, 1.0);
    A.set(2, 2, 2.0);
    
    print("Original Matrix A:");
    print("[[2, 1, 0]");
    print(" [1, 3, 1]");
    print(" [0, 1, 2]]");
    
    // Compute dominant eigenvalue
    let (eigenvalue, eigenvector) = AdvancedLinAlg::power_iteration(A, 20);
    
    print("Dominant Eigenvalue: computed");
    print("Eigenvector: computed");
    print("Iterations: 20");
    
    print("");
}

// ============================================================
// Example 5: Least Squares Problem
// ============================================================

fn example_least_squares() {
    print("═══════════════════════════════════════════════════════");
    print("Example 5: Least Squares Problem");
    print("═══════════════════════════════════════════════════════");
    
    // Overdetermined system: Ax = b
    let mut A = Matrix::new(4, 2);
    A.set(0, 0, 1.0);
    A.set(0, 1, 1.0);
    A.set(1, 0, 2.0);
    A.set(1, 1, 1.0);
    A.set(2, 0, 3.0);
    A.set(2, 1, 1.0);
    A.set(3, 0, 4.0);
    A.set(3, 1, 1.0);
    
    let mut b = Matrix::new(4, 1);
    b.set(0, 0, 2.0);
    b.set(1, 0, 3.0);
    b.set(2, 0, 4.0);
    b.set(3, 0, 5.0);
    
    print("Overdetermined System:");
    print("A shape: [4, 2]");
    print("b shape: [4, 1]");
    print("Solving: min ||Ax - b||^2");
    
    // Solve using QR decomposition
    let x = AdvancedLinAlg::least_squares(A, b);
    
    print("Solution x computed");
    print("x shape: [2, 1]");
    
    print("");
}

// ============================================================
// Example 6: Gradient Descent Optimization
// ============================================================

fn example_gradient_descent() {
    print("═══════════════════════════════════════════════════════");
    print("Example 6: Gradient Descent Optimization");
    print("═══════════════════════════════════════════════════════");
    
    // Minimize Rosenbrock function
    let initial_x = List::from([0.0, 0.0]);
    
    print("Minimizing Rosenbrock function:");
    print("f(x,y) = (1-x)^2 + 100(y-x^2)^2");
    print("Initial point: [0, 0]");
    print("Learning rate: 0.01");
    print("Max iterations: 100");
    
    let result = Optimizer::gradient_descent(initial_x, 0.01, 100, 1e-6);
    
    print("Optimization completed");
    print("Iterations: " + result.iterations);
    print("Final value: computed");
    print("Converged: " + result.converged);
    
    print("");
}

// ============================================================
// Example 7: Adam Optimizer
// ============================================================

fn example_adam_optimizer() {
    print("═══════════════════════════════════════════════════════");
    print("Example 7: Adam Optimizer");
    print("═══════════════════════════════════════════════════════");
    
    // Minimize Rosenbrock function with Adam
    let initial_x = List::from([0.0, 0.0]);
    
    print("Minimizing Rosenbrock function with Adam:");
    print("f(x,y) = (1-x)^2 + 100(y-x^2)^2");
    print("Initial point: [0, 0]");
    print("Learning rate: 0.001");
    print("Beta1: 0.9, Beta2: 0.999");
    print("Max iterations: 100");
    
    let result = Optimizer::adam(initial_x, 0.001, 100, 0.9, 0.999);
    
    print("Optimization completed");
    print("Iterations: " + result.iterations);
    print("Final value: computed");
    print("Converged: " + result.converged);
    
    print("");
}

// ============================================================
// Example 8: Matrix Norms
// ============================================================

fn example_matrix_norms() {
    print("═══════════════════════════════════════════════════════");
    print("Example 8: Matrix Norms");
    print("═══════════════════════════════════════════════════════");
    
    let mut A = Matrix::new(3, 3);
    A.set(0, 0, 1.0);
    A.set(0, 1, 2.0);
    A.set(0, 2, 3.0);
    A.set(1, 0, 4.0);
    A.set(1, 1, 5.0);
    A.set(1, 2, 6.0);
    A.set(2, 0, 7.0);
    A.set(2, 1, 8.0);
    A.set(2, 2, 9.0);
    
    print("Matrix A:");
    print("[[1, 2, 3]");
    print(" [4, 5, 6]");
    print(" [7, 8, 9]]");
    
    // Compute Frobenius norm
    let frob_norm = AdvancedLinAlg::norm_frobenius(A);
    print("Frobenius norm: computed");
    
    // Compute spectral norm
    let spec_norm = AdvancedLinAlg::norm_spectral(A);
    print("Spectral norm: computed");
    
    print("");
}

// ============================================================
// Run All Examples
// ============================================================

fn run_all_phase2_examples() {
    print("╔════════════════════════════════════════════════════════╗");
    print("║     Phase 2 Examples - FFI & Advanced Linear Algebra   ║");
    print("╚════════════════════════════════════════════════════════╝");
    print("");
    
    example_numpy_array_creation();
    example_qr_decomposition();
    example_cholesky_decomposition();
    example_eigenvalue_computation();
    example_least_squares();
    example_gradient_descent();
    example_adam_optimizer();
    example_matrix_norms();
    
    print("╔════════════════════════════════════════════════════════╗");
    print("║        ✅ All Phase 2 Examples Completed!             ║");
    print("╚════════════════════════════════════════════════════════╝");
}

